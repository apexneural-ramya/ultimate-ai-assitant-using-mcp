# ============================================
# Backend Environment Variables (.env)
# ============================================
# Copy this file to .env and fill in your actual values
# cp .env.example .env

# ============================================
# REQUIRED: Backend Server Configuration
# ============================================
# Backend server host (e.g., 0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
BACKEND_HOST=0.0.0.0

# Backend server port
BACKEND_PORT=8000

# Frontend URL for CORS (must match your frontend URL)
FRONTEND_URL=http://localhost:3000

# ============================================
# REQUIRED: LLM Configuration
# ============================================
# Option 1: Use OpenRouter (recommended for cloud models)
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Option 2: Use OpenAI directly (uncomment and provide key instead of OpenRouter)
# OPENAI_API_KEY=your-openai-api-key-here

# ============================================
# OPTIONAL: LLM Model Configuration
# ============================================
# LLM model name (default: openai/gpt-4o-mini)
# Examples:
#   - openai/gpt-4o-mini (OpenRouter)
#   - openai/gpt-4o (OpenRouter)
#   - qwen2.5:7b (Ollama - if using local LLM)
LLM_MODEL=openai/gpt-4o-mini

# OpenRouter API base URL (default: https://openrouter.ai/api/v1)
# Only needed if using OpenRouter
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Maximum steps for the MCP agent (default: 100)
MCP_MAX_STEPS=100

# ============================================
# REQUIRED: MCP Server API Keys
# ============================================
# Firecrawl MCP - Web scraping and crawling
# Get your API key at: https://firecrawl.dev/
FIRECRAWL_API_KEY=your-firecrawl-api-key-here

# Ragie MCP - Multimodal RAG
# Get your API key at: https://ragie.ai/
RAGIE_API_KEY=your-ragie-api-key-here

# ============================================
# Frontend Environment Variables (.env.local)
# ============================================
# Create a .env.local file in the frontend/ directory with:
# BACKEND_URL=http://localhost:8000
#
# Note: Replace localhost:8000 with your actual backend URL and port
# if you're running the backend on a different host/port
